{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73757f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import scipy.spatial.distance \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torchvision import transforms, utils \n",
    "import torch.nn.functional as F\n",
    "from time import time\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4d5a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46d74392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/parvez/Dataset/ModelNet40_dataset/ModelNet40\n"
     ]
    }
   ],
   "source": [
    "path=os.path.join(\"/home/parvez\",\"Dataset/ModelNet40_dataset/ModelNet40\")\n",
    "print(path)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2f16e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders=[dir for dir in sorted(os.listdir(path))]\n",
    "classes={folder:i for i, folder in enumerate(folders)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "896eb58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_off(file):\n",
    "    off_header = file.readline().strip()\n",
    "    if 'OFF' == off_header:\n",
    "        n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])\n",
    "    else:\n",
    "        n_verts, n_faces, __ = tuple([int(s) for s in off_header[3:].split(' ')])\n",
    "    verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n",
    "    faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n",
    "    return verts, faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95f1cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path, 'bed/train/bed_0001.off'),'r') as f:\n",
    "    verts, faces=read_off(f)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2031cc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i,j,k=np.array(faces).T\n",
    "x,y,z=np.array(verts).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0474afb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointSampler(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size,int)\n",
    "        self.output_size=output_size\n",
    "        \n",
    "    def triangle_area(self, pt1, pt2, pt3):\n",
    "        side_a=np.linalg.norm(pt1-pt2)\n",
    "        side_b=np.linalg.norm(pt2-pt3)\n",
    "        side_c=np.linalg.norm(pt3-pt1)\n",
    "        s=0.5*(side_a+side_b+side_c)\n",
    "        return max(s*(s-side_a)*(s-side_b)*(s-side_c),0)**0.5\n",
    "    \n",
    "    def sample_point(self, pt1,pt2,pt3):\n",
    "        s,t=sorted([random.random(), random.random()])\n",
    "        f=lambda i: s*pt1[i]+(t-s)*pt2[i]+(1-t)*pt3[i]\n",
    "        return (f(0), f(1), f(2))\n",
    "    \n",
    "    def __call__(self, mesh):\n",
    "        verts, faces=mesh\n",
    "        verts=np.array(verts)\n",
    "        areas=np.zeros((len(faces)))\n",
    "        for i in range(len(areas)):\n",
    "            areas[i]=(self.triangle_area(verts[faces[i][0]],\n",
    "                                       verts[faces[i][1]],\n",
    "                                       verts[faces[i][2]]))\n",
    "            \n",
    "        sampled_faces=(random.choices(faces,\n",
    "                                     weights=areas,\n",
    "                                     cum_weights=None,\n",
    "                                     k=self.output_size))\n",
    "        \n",
    "        sampled_points=np.zeros((self.output_size, 3))\n",
    "        for i in range(len(sampled_faces)):\n",
    "            sampled_points[i]=(self.sample_point(verts[sampled_faces[i][0]],\n",
    "                                                verts[sampled_faces[i][1]],\n",
    "                                                verts[sampled_faces[i][2]]))\n",
    "            \n",
    "        return sampled_points\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f98f7650",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointcloud=PointSampler(3000)((verts, faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b791d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(pointcloud.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cb07c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "        \n",
    "        norm_pointcloud=pointcloud -  np.mean(pointcloud, axis=0)\n",
    "        norm_pointcloud /=np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
    "        \n",
    "        return norm_pointcloud\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4479e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_pointcloud = Normalize()(pointcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ab0ea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "        return torch.from_numpy(pointcloud)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7328917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_transforms():\n",
    "    return transforms.Compose([\n",
    "        PointSampler(1024),\n",
    "        Normalize(),\n",
    "        ToTensor()\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a34eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudData(Dataset):\n",
    "    def __init__(self,root_dir, valid=False, folder='train', transform=default_transforms()):\n",
    "        self.root_dir=root_dir\n",
    "        folders=[dir for dir in sorted(os.listdir(root_dir))]\n",
    "        self.classes={folder:i for i, folder in enumerate(folders)}\n",
    "        self.transforms=transform if not valid else default_transforms()\n",
    "        self.valid=valid\n",
    "        self.files=[]\n",
    "        for category in self.classes.keys():\n",
    "            new_dir=os.path.join(root_dir, category, folder)\n",
    "            for file in os.listdir(new_dir):\n",
    "                if file.endswith('.off'):\n",
    "                    sample={}\n",
    "                    sample['pcd_path']=os.path.join(new_dir, file)\n",
    "                    sample['category']=category\n",
    "                    self.files.append(sample)\n",
    "                    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    \n",
    "    def __preproc__(self, file):\n",
    "        verts, faces=read_off(file)\n",
    "        if self.transforms:\n",
    "            pointcloud=self.transforms((verts, faces))\n",
    "        \n",
    "        return pointcloud \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pcd_path=self.files[idx]['pcd_path']\n",
    "        category=self.files[idx]['category']\n",
    "        with open(pcd_path, 'r') as f:\n",
    "            pointcloud=self.__preproc__(f)\n",
    "        return {'pointcloud' : pointcloud,\n",
    "                'category' : self.classes[category]}\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ba9cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=PointCloudData(path)\n",
    "valid_ds=PointCloudData(path, valid=True, folder='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee659233",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(dataset=train_ds, batch_size=32, shuffle=True)\n",
    "valid_loader=DataLoader(dataset=valid_ds, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e4bdfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fps(pcd,n_samples):\n",
    "    B,N,D=pcd.shape\n",
    "    kernel=torch.zeros(B,n_samples,D)\n",
    "    \n",
    "    \n",
    "    for n in range(B):\n",
    "        \n",
    "        points=np.array(pcd[n])\n",
    "        \n",
    "        points_left=np.arange(len(points))\n",
    "        \n",
    "        sample_inds=np.zeros(n_samples,dtype='int')\n",
    "        \n",
    "        dists=np.ones_like(points_left)*float('inf')\n",
    "        \n",
    "        selected=0\n",
    "        sample_inds[0]=points_left[selected]\n",
    "        \n",
    "        points_left=np.delete(points_left,selected)\n",
    "        \n",
    "        for i in range(1, n_samples):\n",
    "            \n",
    "            last_added=sample_inds[i-1]\n",
    "            \n",
    "            dist_to_last_added_point =((points[last_added]-points[points_left])**2).sum(-1)\n",
    "            \n",
    "            dists[points_left]=np.minimum(dist_to_last_added_point, dists[points_left])\n",
    "            \n",
    "            selected=np.argmax(dists[points_left])\n",
    "            sample_inds[i]=points_left[selected]\n",
    "            \n",
    "            points_left=np.delete(points_left, selected)\n",
    "            \n",
    "        kernel[n]=torch.from_numpy(points[sample_inds])\n",
    "    \n",
    "    return kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac4cd212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(x,k):\n",
    "    inner=-2*torch.matmul(x.transpose(2,1).contiguous(),x)\n",
    "    xx=torch.sum(x**2,dim=1,keepdim=True)\n",
    "    pairwise_distance=-xx-inner-xx.transpose(2,1).contiguous()\n",
    "    \n",
    "    idx=pairwise_distance.topk(k=k,dim=-1)[1]\n",
    "    \n",
    "    return idx    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb6479e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_feature(x,k=20):\n",
    "    \n",
    "    idx=knn(x, k=k) # (batch_size, num_points, k)\n",
    "    batch_size, num_points, _ =idx.size()\n",
    "    \n",
    "    device=torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    \n",
    "    idx_base=torch.arange(0,batch_size).view(-1,1,1)*num_points\n",
    "    \n",
    "    idx=idx+idx_base\n",
    "    \n",
    "    idx=idx.view(-1)\n",
    "    \n",
    "    _,num_dims,_=x.size()\n",
    "    \n",
    "    x=x.transpose(2,1).contiguous()\n",
    "    \n",
    "    feature=x.view(batch_size*num_points,-1)[idx,:]\n",
    "    feature=feature.view(batch_size,num_points,k,num_dims)\n",
    "    x=x.view(batch_size, num_points, 1,num_dims).repeat(1,1,k,1)\n",
    "    \n",
    "    feature=torch.cat((feature,x),dim=3).permute(0,3,1,2)\n",
    "    \n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92d5a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGCNN(nn.Module):\n",
    "    def __init__(self,emb_dims=1024, input_shape=\"bnc\"):\n",
    "        super(DGCNN,self).__init__()\n",
    "        if input_shape not in [\"bcn\",\"bnc\"]:\n",
    "            raise ValueError(\"Allowed shapes are 'bcn' (batch*channels*num_in_points),'bnc' \")\n",
    "        self.input_shape=input_shape\n",
    "        self.emb_dims=emb_dims\n",
    "        \n",
    "        self.conv1=nn.Conv2d(6,64,kernel_size=1,bias=False)\n",
    "        self.conv2=nn.Conv2d(64,64,kernel_size=1,bias=False)\n",
    "        self.conv3=nn.Conv2d(64,128,kernel_size=1,bias=False)\n",
    "        self.conv4=nn.Conv2d(128,256,kernel_size=1,bias=False)\n",
    "        self.conv5=nn.Conv2d(512,emb_dims,kernel_size=1, bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(64)\n",
    "        self.bn2=nn.BatchNorm2d(64)\n",
    "        self.bn3=nn.BatchNorm2d(128)\n",
    "        self.bn4=nn.BatchNorm2d(256)\n",
    "        self.bn5=nn.BatchNorm2d(emb_dims)\n",
    "        \n",
    "    def forward(self,input_data):\n",
    "        if self.input_shape==\"bnc\":\n",
    "            input_data=input_data.permute(0,2,1)\n",
    "        if input_data.shape[1]!=3:\n",
    "            raise RuntimeError(\"shape of x must be of [Batch x 3 x NumInPoints]\")\n",
    "        \n",
    "        batch_size, num_dims, num_points=input_data.size()\n",
    "        output=get_graph_feature(input_data)\n",
    "        \n",
    "        output=F.relu(self.bn1(self.conv1(output)))\n",
    "        output1=output.max(dim=-1,keepdim=True)[0]\n",
    "        \n",
    "        output=F.relu(self.bn2(self.conv2(output)))\n",
    "        output2=output.max(dim=-1,keepdim=True)[0]\n",
    "        \n",
    "        output=F.relu(self.bn3(self.conv3(output)))\n",
    "        output3=output.max(dim=-1,keepdim=True)[0]\n",
    "        \n",
    "        output=F.relu(self.bn4(self.conv4(output)))\n",
    "        output4=output.max(dim=-1,keepdim=True)[0]\n",
    "        \n",
    "        output=torch.cat((output1, output2, output3, output4), dim=1)\n",
    "        \n",
    "        output=F.relu(self.bn5(self.conv5(output))).view(batch_size,num_points,-1)\n",
    "        \n",
    "        return output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17136663",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SelfAttention,self).__init__()\n",
    "        \n",
    "        self.softmax=nn.Softmax(dim=2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        B,N,D=x.shape\n",
    "        scale=D ** -0.5\n",
    "        \n",
    "        q = x\n",
    "        k = x\n",
    "        v = x\n",
    "        \n",
    "        weights=self.softmax(torch.bmm(q, k.transpose(1,2))) * scale\n",
    "        \n",
    "        attn_value = torch.bmm(weights, v)\n",
    "        \n",
    "        return attn_value\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c658b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder,self).__init__()\n",
    "        \n",
    "        self.self_attn=SelfAttention()\n",
    "        \n",
    "        self.dgcnn=DGCNN()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        B,N,dim=x.shape\n",
    "        \n",
    "        self.fc1=nn.Linear(dim,64)\n",
    "        self.fc2=nn.Linear(64,3)\n",
    "        \n",
    "        out=F.relu(self.fc1(x))\n",
    "        out=F.relu(self.fc2(out))\n",
    "        \n",
    "        \n",
    "        \n",
    "        attn=self.self_attn(x)\n",
    "        \n",
    "        out=self.dgcnn(out)\n",
    "       \n",
    "       \n",
    "        \n",
    "        out=torch.cat([out,attn],dim=2)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a2fd389",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossAttention,self).__init__()\n",
    "        \n",
    "        self.softmax=nn.Softmax(dim=2)\n",
    "        \n",
    "        \n",
    "    def forward(self,q,v):\n",
    "        \n",
    "        B,N,D=q.shape\n",
    "        scale=D ** -0.5\n",
    "        \n",
    "        k=v\n",
    "        \n",
    "        weights=self.softmax(torch.bmm(q,v.transpose(1,2)))\n",
    "        attn_value=torch.bmm(weights, v)\n",
    "        \n",
    "        return attn_value\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac51cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder,self).__init__()\n",
    "        \n",
    "       \n",
    "        \n",
    "        self.cross_attn=CrossAttention()\n",
    "        \n",
    "        self.dgcnn=DGCNN()\n",
    "        \n",
    "    def forward(self, q,v):\n",
    "        \n",
    "        B,N,dim=v.shape\n",
    "        \n",
    "        self.fc1=nn.Linear(dim,64)\n",
    "        self.fc2=nn.Linear(64,3)\n",
    "        \n",
    "        out=F.relu(self.fc1(v))\n",
    "        out=F.relu(self.fc2(out))\n",
    "        \n",
    "        attn=self.cross_attn(q,v)\n",
    "        \n",
    "        out=self.dgcnn(out)\n",
    "        \n",
    "        out=torch.cat((out,attn),dim=2)\n",
    "        \n",
    "        return out\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7527317",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryGenerator(nn.Module):\n",
    "    def __init__(self,dim):\n",
    "        super(QueryGenerator,self).__init__()\n",
    "        \n",
    "        self.dim=dim\n",
    "        \n",
    "        self.fc1=nn.Linear(dim,64)\n",
    "        self.fc2=nn.Linear(64,128)\n",
    "        self.fc3=nn.Linear(128,256)\n",
    "        \n",
    "        # for generating coordinates\n",
    "        self.fc4=nn.Linear(dim,64)\n",
    "        self.fc5=nn.Linear(64,128)\n",
    "        self.fc6=nn.Linear(128,256)\n",
    "        self.fc7=nn.Linear(256,128)\n",
    "        self.fc8=nn.Linear(128,64)\n",
    "        self.fc9=nn.Linear(64,3)\n",
    "        \n",
    "        # for generating query embeddings\n",
    "        self.fc10=nn.Linear(4,64)\n",
    "        self.fc11=nn.Linear(64,128)\n",
    "        self.fc12=nn.Linear(128,dim)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        # generation of global feature g\n",
    "        f=x\n",
    "        f=F.relu(self.fc1(f))\n",
    "        f=F.relu(self.fc2(f))\n",
    "        f=F.relu(self.fc3(f))\n",
    "        \n",
    "        g=torch.max(f,dim=2,keepdim=True)[0]\n",
    "        \n",
    "        coordinate=F.relu(self.fc4(x))\n",
    "        coordinate=F.relu(self.fc5(coordinate))\n",
    "        coordinate=F.relu(self.fc6(coordinate))\n",
    "        coordinate=F.relu(self.fc7(coordinate))\n",
    "        coordinate=F.relu(self.fc8(coordinate))\n",
    "        coordinate=F.relu(self.fc9(coordinate))\n",
    "        \n",
    "        # concatination of g and coordinate\n",
    "        \n",
    "        q_emb=torch.cat((coordinate,g),dim=2)\n",
    "        \n",
    "        q_emb=F.relu(self.fc10(q_emb))\n",
    "        q_emb=F.relu(self.fc11(q_emb))\n",
    "        q_emb=F.relu(self.fc12(q_emb))\n",
    "        \n",
    "        return coordinate, q_emb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9df6450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoldingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(FoldingNet,self).__init__()\n",
    "        \n",
    "        \n",
    "    def forward(self,input):\n",
    "        B,N,d=input.shape\n",
    "        \n",
    "        m =2050\n",
    "        grid=torch.randn(B,m,2)\n",
    "        \n",
    "        codeword=torch.max(input,dim=1, keepdim=True)[0].repeat(1,m,1)\n",
    "        \n",
    "        feature=torch.cat((codeword,grid),dim=2)\n",
    "        \n",
    "        self.fc1=nn.Linear(d+2, 256)\n",
    "        self.fc2=nn.Linear(256,128)\n",
    "        self.fc3=nn.Linear(128,3)\n",
    "        \n",
    "        feature=F.relu(self.fc1(feature))\n",
    "        feature=F.relu(self.fc2(feature))\n",
    "        feature=F.relu(self.fc3(feature))\n",
    "        \n",
    "        feature=torch.cat((feature,codeword),dim=2)\n",
    "        \n",
    "        self.fc4=nn.Linear(d+3,256)\n",
    "        self.fc5=nn.Linear(256,128)\n",
    "        self.fc6=nn.Linear(128,3)\n",
    "        \n",
    "        out=F.relu(self.fc4(feature))\n",
    "        out=F.relu(self.fc5(out))\n",
    "        out=F.relu(self.fc6(out))\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ab9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChamferDistance(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChamferDistance,self).__init__()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e65bfb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoinTr(nn.Module):\n",
    "    def __init__(self,num_samples=50):\n",
    "        super(PoinTr,self).__init__()\n",
    "        \n",
    "        self.num_samples=num_samples\n",
    "        \n",
    "        self.fc1=nn.Linear(3,64)\n",
    "        self.fc2=nn.Linear(64,128)\n",
    "        self.fc3=nn.Linear(128,256)\n",
    "        self.fc4=nn.Linear(256,128)\n",
    "        self.fc5=nn.Linear(128,64)\n",
    "        \n",
    "        self.dgcnn=DGCNN()\n",
    "        \n",
    "        self.encoder=Encoder()\n",
    "        \n",
    "        self.decoder=Decoder()\n",
    "        \n",
    "        self.foldingNet=FoldingNet()\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        B,N,D=input.shape\n",
    "    \n",
    "        kernels=fps(input,self.num_samples)\n",
    "        x=kernels\n",
    "        \n",
    "        \n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=F.relu(self.fc3(x))\n",
    "        x=F.relu(self.fc4(x))\n",
    "        x=F.relu(self.fc5(x))\n",
    "        \n",
    "        F_i=self.dgcnn(kernels)\n",
    "        F_i=torch.cat((F_i,x),dim=2)\n",
    "        \n",
    "        encoded_point_proxies=self.encoder(F_i)\n",
    "        \n",
    "        _,_,dim=encoded_point_proxies.shape\n",
    "        \n",
    "        self.q_gen=QueryGenerator(dim)\n",
    "        \n",
    "        coordinate,q_emb=self.q_gen(encoded_point_proxies)\n",
    "        \n",
    "        predicted_proxies=self.decoder(q_emb,encoded_point_proxies)\n",
    "        \n",
    "        predicted_pcd=self.foldingNet(predicted_proxies)\n",
    "        coordinate=coordinate.repeat(1,41,1)\n",
    "        \n",
    "        predicted_pcd=predicted_pcd+coordinate\n",
    "        \n",
    "        complete_pcd=torch.cat((input,predicted_pcd),dim=1)\n",
    "        \n",
    "        \n",
    "        return complete_pcd\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8060725",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1868f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff3f2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a9cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c89118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce7343d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a2713d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ee2436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
